{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD didnt work, not enough signal, too many dimensions\n",
    "\n",
    "- reduce the dimensions\n",
    "\n",
    "- incease the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split, KFold, cross_val_score\n",
    "import sklearn.metrics as sk\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({u'Black': 1576,\n",
       "         u'Blue': 1573,\n",
       "         u'Green': 1566,\n",
       "         u'Red': 1575,\n",
       "         u'White': 1584})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modern = pd.read_pickle('data/5color_modern_no_name_hardmode.pkl')\n",
    "Counter(modern.colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1,161 words in the vocabulary.\n"
     ]
    }
   ],
   "source": [
    "modern['bincolor'] = pd.Categorical.from_array(modern.colors).codes\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "y = modern.bincolor\n",
    "\n",
    "X = vectorizer.fit_transform(modern.text)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "print \"There are {:,} words in the vocabulary.\".format(len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.702\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C=2, multi_class='ovr', solver='liblinear')\n",
    "\n",
    "acc = cross_val_score(clf, X_train, y_train,\n",
    "                       cv=10, scoring='accuracy') \n",
    "\n",
    "print \"Accuracy: %s\" % acc.mean().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1,161 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 1,161 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 1,161 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 1,161 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 1,160 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 1,150 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 1,140 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 1,130 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 1,120 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 1,110 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 1,100 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 1,090 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 1,080 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 1,070 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 1,060 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 1,050 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 1,040 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 1,030 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 1,020 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 1,010 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 1,000 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 990 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 980 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 970 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 960 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 950 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 940 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 930 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 920 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 910 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 900 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 890 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 880 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 870 words in the vocabulary.\n",
      "Accuracy: 0.697\n",
      "There are 860 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 850 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 840 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 830 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 820 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 810 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 800 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 790 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 780 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 770 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 760 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 750 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 740 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 730 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 720 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 710 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 700 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 690 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 680 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 670 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 660 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 650 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 640 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 630 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 620 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 610 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 600 words in the vocabulary.\n",
      "Accuracy: 0.698\n",
      "There are 590 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 580 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 570 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 560 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 550 words in the vocabulary.\n",
      "Accuracy: 0.7\n",
      "There are 540 words in the vocabulary.\n",
      "Accuracy: 0.7\n",
      "There are 530 words in the vocabulary.\n",
      "Accuracy: 0.7\n",
      "There are 520 words in the vocabulary.\n",
      "Accuracy: 0.699\n",
      "There are 510 words in the vocabulary.\n",
      "Accuracy: 0.7\n",
      "There are 500 words in the vocabulary.\n",
      "Accuracy: 0.696\n",
      "There are 490 words in the vocabulary.\n",
      "Accuracy: 0.695\n",
      "There are 480 words in the vocabulary.\n",
      "Accuracy: 0.695\n",
      "There are 470 words in the vocabulary.\n",
      "Accuracy: 0.694\n",
      "There are 460 words in the vocabulary.\n",
      "Accuracy: 0.693\n",
      "There are 450 words in the vocabulary.\n",
      "Accuracy: 0.693\n",
      "There are 440 words in the vocabulary.\n",
      "Accuracy: 0.693\n",
      "There are 430 words in the vocabulary.\n",
      "Accuracy: 0.692\n",
      "There are 420 words in the vocabulary.\n",
      "Accuracy: 0.692\n",
      "There are 410 words in the vocabulary.\n",
      "Accuracy: 0.69\n",
      "There are 400 words in the vocabulary.\n",
      "Accuracy: 0.693\n",
      "There are 390 words in the vocabulary.\n",
      "Accuracy: 0.692\n",
      "There are 380 words in the vocabulary.\n",
      "Accuracy: 0.691\n",
      "There are 370 words in the vocabulary.\n",
      "Accuracy: 0.689\n",
      "There are 360 words in the vocabulary.\n",
      "Accuracy: 0.687\n",
      "There are 350 words in the vocabulary.\n",
      "Accuracy: 0.687\n",
      "There are 340 words in the vocabulary.\n",
      "Accuracy: 0.686\n",
      "There are 330 words in the vocabulary.\n",
      "Accuracy: 0.686\n",
      "There are 320 words in the vocabulary.\n",
      "Accuracy: 0.684\n",
      "There are 310 words in the vocabulary.\n",
      "Accuracy: 0.677\n",
      "There are 300 words in the vocabulary.\n",
      "Accuracy: 0.676\n",
      "There are 290 words in the vocabulary.\n",
      "Accuracy: 0.675\n",
      "There are 280 words in the vocabulary.\n",
      "Accuracy: 0.676\n",
      "There are 270 words in the vocabulary.\n",
      "Accuracy: 0.676\n",
      "There are 260 words in the vocabulary.\n",
      "Accuracy: 0.668\n",
      "There are 250 words in the vocabulary.\n",
      "Accuracy: 0.665\n",
      "There are 240 words in the vocabulary.\n",
      "Accuracy: 0.663\n",
      "There are 230 words in the vocabulary.\n",
      "Accuracy: 0.661\n",
      "There are 220 words in the vocabulary.\n",
      "Accuracy: 0.66\n",
      "There are 210 words in the vocabulary.\n",
      "Accuracy: 0.649\n",
      "There are 200 words in the vocabulary.\n",
      "Accuracy: 0.651\n",
      "There are 190 words in the vocabulary.\n",
      "Accuracy: 0.649\n",
      "There are 180 words in the vocabulary.\n",
      "Accuracy: 0.648\n",
      "There are 170 words in the vocabulary.\n",
      "Accuracy: 0.639\n",
      "There are 160 words in the vocabulary.\n",
      "Accuracy: 0.633\n",
      "There are 150 words in the vocabulary.\n",
      "Accuracy: 0.622\n",
      "There are 140 words in the vocabulary.\n",
      "Accuracy: 0.615\n",
      "There are 130 words in the vocabulary.\n",
      "Accuracy: 0.606\n",
      "There are 120 words in the vocabulary.\n",
      "Accuracy: 0.602\n",
      "There are 110 words in the vocabulary.\n",
      "Accuracy: 0.574\n",
      "There are 100 words in the vocabulary.\n",
      "Accuracy: 0.572\n",
      "There are 90 words in the vocabulary.\n",
      "Accuracy: 0.539\n",
      "There are 80 words in the vocabulary.\n",
      "Accuracy: 0.528\n",
      "There are 70 words in the vocabulary.\n",
      "Accuracy: 0.505\n",
      "There are 60 words in the vocabulary.\n",
      "Accuracy: 0.5\n",
      "There are 50 words in the vocabulary.\n",
      "Accuracy: 0.475\n",
      "There are 40 words in the vocabulary.\n",
      "Accuracy: 0.463\n",
      "There are 30 words in the vocabulary.\n",
      "Accuracy: 0.42\n",
      "There are 20 words in the vocabulary.\n",
      "Accuracy: 0.388\n"
     ]
    }
   ],
   "source": [
    "n=1200\n",
    "num_feat = []\n",
    "acc_feat = []\n",
    "\n",
    "for i in xrange(n/10 -1):\n",
    "    vectorizer = CountVectorizer(max_features=n)\n",
    "\n",
    "    X = vectorizer.fit_transform(modern.text)\n",
    "    \n",
    "    num_feat += [len(vectorizer.vocabulary_)]\n",
    "\n",
    "    print \"There are {:,} words in the vocabulary.\".format(len(vectorizer.vocabulary_))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    \n",
    "    clf = LogisticRegression(C=2, multi_class='ovr', solver='liblinear')\n",
    "\n",
    "    acc = cross_val_score(clf, X_train, y_train,\n",
    "                           cv=7, scoring='accuracy') \n",
    "    \n",
    "    acc_feat += [acc.mean()]\n",
    "\n",
    "    print \"Accuracy: %s\" % acc.mean().round(3)\n",
    "    \n",
    "    n -= 10\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1161,\n",
       " 1161,\n",
       " 1161,\n",
       " 1161,\n",
       " 1160,\n",
       " 1150,\n",
       " 1140,\n",
       " 1130,\n",
       " 1120,\n",
       " 1110,\n",
       " 1100,\n",
       " 1090,\n",
       " 1080,\n",
       " 1070,\n",
       " 1060,\n",
       " 1050,\n",
       " 1040,\n",
       " 1030,\n",
       " 1020,\n",
       " 1010,\n",
       " 1000,\n",
       " 990,\n",
       " 980,\n",
       " 970,\n",
       " 960,\n",
       " 950,\n",
       " 940,\n",
       " 930,\n",
       " 920,\n",
       " 910,\n",
       " 900,\n",
       " 890,\n",
       " 880,\n",
       " 870,\n",
       " 860,\n",
       " 850,\n",
       " 840,\n",
       " 830,\n",
       " 820,\n",
       " 810,\n",
       " 800,\n",
       " 790,\n",
       " 780,\n",
       " 770,\n",
       " 760,\n",
       " 750,\n",
       " 740,\n",
       " 730,\n",
       " 720,\n",
       " 710,\n",
       " 700,\n",
       " 690,\n",
       " 680,\n",
       " 670,\n",
       " 660,\n",
       " 650,\n",
       " 640,\n",
       " 630,\n",
       " 620,\n",
       " 610,\n",
       " 600,\n",
       " 590,\n",
       " 580,\n",
       " 570,\n",
       " 560,\n",
       " 550,\n",
       " 540,\n",
       " 530,\n",
       " 520,\n",
       " 510,\n",
       " 500,\n",
       " 490,\n",
       " 480,\n",
       " 470,\n",
       " 460,\n",
       " 450,\n",
       " 440,\n",
       " 430,\n",
       " 420,\n",
       " 410,\n",
       " 400,\n",
       " 390,\n",
       " 380,\n",
       " 370,\n",
       " 360,\n",
       " 350,\n",
       " 340,\n",
       " 330,\n",
       " 320,\n",
       " 310,\n",
       " 300,\n",
       " 290,\n",
       " 280,\n",
       " 270,\n",
       " 260,\n",
       " 250,\n",
       " 240,\n",
       " 230,\n",
       " 220,\n",
       " 210,\n",
       " 200,\n",
       " 190,\n",
       " 180,\n",
       " 170,\n",
       " 160,\n",
       " 150,\n",
       " 140,\n",
       " 130,\n",
       " 120,\n",
       " 110,\n",
       " 100,\n",
       " 90,\n",
       " 80,\n",
       " 70,\n",
       " 60,\n",
       " 50,\n",
       " 40,\n",
       " 30,\n",
       " 20]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.69889547998747514,\n",
       " 0.69889547998747514,\n",
       " 0.69889547998747514,\n",
       " 0.69889547998747514,\n",
       " 0.69889547998747514,\n",
       " 0.69889547998747514,\n",
       " 0.69906474295723464,\n",
       " 0.6988948781067722,\n",
       " 0.69838749172196635,\n",
       " 0.69838709062657478,\n",
       " 0.69821802891905149,\n",
       " 0.69821802891905149,\n",
       " 0.69872601670932888,\n",
       " 0.69838729093665464,\n",
       " 0.69821822922913135,\n",
       " 0.69855655295425811,\n",
       " 0.69838749124673483,\n",
       " 0.69872561466178118,\n",
       " 0.69923340357276087,\n",
       " 0.69838809503514465,\n",
       " 0.69821923363770144,\n",
       " 0.69855715674266794,\n",
       " 0.698726820807819,\n",
       " 0.69872621845019123,\n",
       " 0.69838809503514465,\n",
       " 0.6982188325423101,\n",
       " 0.69906474343755398,\n",
       " 0.69906514453294555,\n",
       " 0.69838809503514465,\n",
       " 0.69855775910029572,\n",
       " 0.69855755879021586,\n",
       " 0.69838849708269257,\n",
       " 0.69771104553734398,\n",
       " 0.69737151661833607,\n",
       " 0.69787990502708031,\n",
       " 0.69754158320966086,\n",
       " 0.69788010772009879,\n",
       " 0.69838849517498558,\n",
       " 0.69804916704468345,\n",
       " 0.69889708580491128,\n",
       " 0.69889728754237901,\n",
       " 0.6990665505121384,\n",
       " 0.69906735317984625,\n",
       " 0.6985577581481397,\n",
       " 0.69787970424176871,\n",
       " 0.69872641780472045,\n",
       " 0.69872621654248412,\n",
       " 0.69787869840581107,\n",
       " 0.69770923607812774,\n",
       " 0.6980475602784858,\n",
       " 0.69787629040268773,\n",
       " 0.69770762979055601,\n",
       " 0.69855333942356368,\n",
       " 0.69872420915612654,\n",
       " 0.69804776201934793,\n",
       " 0.69855534823730925,\n",
       " 0.69889347212928044,\n",
       " 0.69821843001783768,\n",
       " 0.69753957344545214,\n",
       " 0.69787870174430022,\n",
       " 0.69821642406395512,\n",
       " 0.69855635312619835,\n",
       " 0.69872762681571732,\n",
       " 0.69889749119094824,\n",
       " 0.6988984975055319,\n",
       " 0.69991407199069544,\n",
       " 0.69957554604947525,\n",
       " 0.70008353717994332,\n",
       " 0.69940769478373099,\n",
       " 0.69974521488729213,\n",
       " 0.69619049839192548,\n",
       " 0.69517492581786355,\n",
       " 0.69466713690348925,\n",
       " 0.69432660357930565,\n",
       " 0.69297149636141342,\n",
       " 0.69297129700348969,\n",
       " 0.69280243512572726,\n",
       " 0.69178444549201146,\n",
       " 0.6917860541642229,\n",
       " 0.6904291384409641,\n",
       " 0.69280082216456351,\n",
       " 0.69195470904983125,\n",
       " 0.69093671940932655,\n",
       " 0.6885662432591525,\n",
       " 0.68653851146469447,\n",
       " 0.68721475638368601,\n",
       " 0.68585684102791755,\n",
       " 0.68585764608025701,\n",
       " 0.68366004991396245,\n",
       " 0.67688232328555764,\n",
       " 0.67637815233745968,\n",
       " 0.67519230999194624,\n",
       " 0.6758669538746499,\n",
       " 0.67637573622318137,\n",
       " 0.66757167664257278,\n",
       " 0.66536805642136676,\n",
       " 0.66333610525516096,\n",
       " 0.66079033588535796,\n",
       " 0.65977315081178567,\n",
       " 0.6492714461575112,\n",
       " 0.65147185953517694,\n",
       " 0.64926903816457138,\n",
       " 0.64842092148228991,\n",
       " 0.63944358224470221,\n",
       " 0.63250502947893217,\n",
       " 0.6223448606615809,\n",
       " 0.61540027383392171,\n",
       " 0.60641992281159784,\n",
       " 0.60151171063380038,\n",
       " 0.57442027562783238,\n",
       " 0.5722128400003168,\n",
       " 0.53885187270370294,\n",
       " 0.52802770499243212,\n",
       " 0.50464979382221076,\n",
       " 0.50007670136042381,\n",
       " 0.47450841803160865,\n",
       " 0.4626562399652589,\n",
       " 0.42014806762332685,\n",
       " 0.38762979910844286]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_feat #= [i.mean() for i in acc_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAECCAYAAAD3vwBsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118a75290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# seaborn.set_style(\"darkgrid\")\n",
    "plt.plot(zip(num_feat, acc_feat))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
