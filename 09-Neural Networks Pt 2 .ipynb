{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split, KFold, cross_val_score\n",
    "import sklearn.metrics as sk\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({u'Black': 1576,\n",
       "         u'Blue': 1573,\n",
       "         u'Green': 1566,\n",
       "         u'Red': 1575,\n",
       "         u'White': 1584})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modern = pd.read_pickle('data/5color_modern_no_name_hardmode.pkl')\n",
    "Counter(modern.colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1,161 words in the vocabulary.\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "y = pd.get_dummies(modern.colors)\n",
    "\n",
    "X = vectorizer.fit_transform(modern.text)\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X, y, random_state=42)\n",
    "\n",
    "xTrain = np.asarray(xTrain.todense())\n",
    "xTest  = np.asarray(xTest.todense())\n",
    "yTrain = np.asarray(yTrain)\n",
    "yTest  = np.asarray(yTest)\n",
    "\n",
    "def shuffle(x, y):\n",
    "    # helper function to shuffle indicies each loop \n",
    "    index = np.random.choice(len(x), len(x), replace=False)\n",
    "    return x[index], y[index]\n",
    "\n",
    "\n",
    "print \"There are {:,} words in the vocabulary.\".format(len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 0     Test: 0.458854166667 Train: 0.507482993197\n",
      "Round: 1     Test: 0.503125       Train: 0.550680272109\n",
      "Round: 2     Test: 0.549479166667 Train: 0.597789115646\n",
      "Round: 3     Test: 0.571875       Train: 0.628741496599\n",
      "Round: 4     Test: 0.6            Train: 0.664455782313\n",
      "Round: 5     Test: 0.627083333333 Train: 0.688945578231\n",
      "Round: 6     Test: 0.638541666667 Train: 0.715136054422\n",
      "Round: 7     Test: 0.659375       Train: 0.736054421769\n",
      "Round: 8     Test: 0.6703125      Train: 0.752721088435\n",
      "Round: 9     Test: 0.675520833333 Train: 0.769047619048\n",
      "Round: 10    Test: 0.684895833333 Train: 0.784013605442\n",
      "Round: 11    Test: 0.6859375      Train: 0.795238095238\n",
      "Round: 12    Test: 0.699479166667 Train: 0.804591836735\n",
      "Round: 13    Test: 0.702083333333 Train: 0.809523809524\n",
      "Round: 14    Test: 0.706770833333 Train: 0.819217687075\n",
      "Round: 15    Test: 0.716145833333 Train: 0.82619047619\n",
      "Round: 16    Test: 0.715104166667 Train: 0.841326530612\n",
      "Round: 17    Test: 0.7171875      Train: 0.845068027211\n",
      "Round: 18    Test: 0.709895833333 Train: 0.852210884354\n",
      "Round: 19    Test: 0.7203125      Train: 0.86156462585\n",
      "Round: 20    Test: 0.721354166667 Train: 0.868197278912\n",
      "Round: 21    Test: 0.719270833333 Train: 0.874829931973\n",
      "Round: 22    Test: 0.723958333333 Train: 0.880442176871\n",
      "Round: 23    Test: 0.720833333333 Train: 0.880102040816\n",
      "Round: 24    Test: 0.730729166667 Train: 0.886904761905\n",
      "Round: 25    Test: 0.724479166667 Train: 0.892857142857\n",
      "Round: 26    Test: 0.729166666667 Train: 0.89880952381\n",
      "Round: 27    Test: 0.720833333333 Train: 0.90612244898\n",
      "Round: 28    Test: 0.725520833333 Train: 0.904931972789\n",
      "Round: 29    Test: 0.721354166667 Train: 0.905442176871\n",
      "Round: 30    Test: 0.726041666667 Train: 0.910204081633\n",
      "Round: 31    Test: 0.722916666667 Train: 0.91343537415\n",
      "Round: 32    Test: 0.721354166667 Train: 0.913945578231\n",
      "Round: 33    Test: 0.7203125      Train: 0.92074829932\n",
      "Round: 34    Test: 0.724479166667 Train: 0.920578231293\n",
      "Round: 35    Test: 0.726041666667 Train: 0.924319727891\n",
      "Round: 36    Test: 0.723958333333 Train: 0.924319727891\n",
      "Round: 37    Test: 0.722916666667 Train: 0.926020408163\n",
      "Round: 38    Test: 0.718229166667 Train: 0.928231292517\n",
      "Round: 39    Test: 0.722916666667 Train: 0.930952380952\n",
      "Round: 40    Test: 0.71875        Train: 0.931802721088\n",
      "Round: 41    Test: 0.7296875      Train: 0.929591836735\n",
      "Round: 42    Test: 0.721875       Train: 0.932823129252\n",
      "Round: 43    Test: 0.719791666667 Train: 0.931802721088\n",
      "Round: 44    Test: 0.719791666667 Train: 0.933503401361\n",
      "Round: 45    Test: 0.719270833333 Train: 0.937925170068\n",
      "Round: 46    Test: 0.721875       Train: 0.935544217687\n",
      "Round: 47    Test: 0.716145833333 Train: 0.936904761905\n",
      "Round: 48    Test: 0.723958333333 Train: 0.93962585034\n",
      "Round: 49    Test: 0.722395833333 Train: 0.941496598639\n",
      "Round: 50    Test: 0.724479166667 Train: 0.943197278912\n",
      "Round: 51    Test: 0.71875        Train: 0.939455782313\n",
      "Round: 52    Test: 0.714583333333 Train: 0.942517006803\n",
      "Round: 53    Test: 0.716666666667 Train: 0.939455782313\n",
      "Round: 54    Test: 0.711458333333 Train: 0.941496598639\n",
      "Round: 55    Test: 0.718229166667 Train: 0.940646258503\n",
      "Round: 56    Test: 0.728645833333 Train: 0.943537414966\n",
      "Round: 57    Test: 0.721354166667 Train: 0.942346938776\n",
      "Round: 58    Test: 0.7203125      Train: 0.948129251701\n",
      "Round: 59    Test: 0.714583333333 Train: 0.94387755102\n",
      "Round: 60    Test: 0.711458333333 Train: 0.940986394558\n",
      "Round: 61    Test: 0.7203125      Train: 0.947278911565\n",
      "Round: 62    Test: 0.725520833333 Train: 0.94387755102\n",
      "Round: 63    Test: 0.723958333333 Train: 0.94574829932\n",
      "Round: 64    Test: 0.721354166667 Train: 0.943707482993\n",
      "Round: 65    Test: 0.719791666667 Train: 0.947108843537\n",
      "Round: 66    Test: 0.721875       Train: 0.947789115646\n",
      "Round: 67    Test: 0.715104166667 Train: 0.948639455782\n",
      "Round: 68    Test: 0.716145833333 Train: 0.944217687075\n",
      "Round: 69    Test: 0.7265625      Train: 0.946598639456\n",
      "Round: 70    Test: 0.734895833333 Train: 0.949319727891\n",
      "Round: 71    Test: 0.723958333333 Train: 0.948129251701\n",
      "Round: 72    Test: 0.721875       Train: 0.944217687075\n",
      "Round: 73    Test: 0.715625       Train: 0.946598639456\n",
      "Round: 74    Test: 0.71875        Train: 0.947789115646\n",
      "Round: 75    Test: 0.7234375      Train: 0.948639455782\n",
      "Round: 76    Test: 0.7203125      Train: 0.949829931973\n",
      "Round: 77    Test: 0.722916666667 Train: 0.948979591837\n",
      "Round: 78    Test: 0.7203125      Train: 0.949659863946\n",
      "Round: 79    Test: 0.719270833333 Train: 0.950680272109\n",
      "Round: 80    Test: 0.721354166667 Train: 0.948979591837\n",
      "Round: 81    Test: 0.7234375      Train: 0.947959183673\n",
      "Round: 82    Test: 0.722395833333 Train: 0.952040816327\n",
      "Round: 83    Test: 0.7125         Train: 0.948639455782\n",
      "Round: 84    Test: 0.725          Train: 0.951870748299\n",
      "Round: 85    Test: 0.7140625      Train: 0.949489795918\n",
      "Round: 86    Test: 0.721354166667 Train: 0.950170068027\n",
      "Round: 87    Test: 0.727083333333 Train: 0.951700680272\n",
      "Round: 88    Test: 0.717708333333 Train: 0.951530612245\n",
      "Round: 89    Test: 0.725520833333 Train: 0.95119047619\n",
      "Round: 90    Test: 0.718229166667 Train: 0.950850340136\n",
      "Round: 91    Test: 0.7234375      Train: 0.949319727891\n",
      "Round: 92    Test: 0.718229166667 Train: 0.950170068027\n",
      "Round: 93    Test: 0.722395833333 Train: 0.949659863946\n",
      "Round: 94    Test: 0.715104166667 Train: 0.952721088435\n",
      "Round: 95    Test: 0.71875        Train: 0.951530612245\n",
      "Round: 96    Test: 0.7140625      Train: 0.95    \n",
      "Round: 97    Test: 0.716145833333 Train: 0.951530612245\n",
      "Round: 98    Test: 0.7203125      Train: 0.948639455782\n",
      "Round: 99    Test: 0.723958333333 Train: 0.949319727891\n",
      "Round: 100   Test: 0.722395833333 Train: 0.951360544218\n",
      "Round: 101   Test: 0.718229166667 Train: 0.950850340136\n",
      "Round: 102   Test: 0.722916666667 Train: 0.951360544218\n",
      "Round: 103   Test: 0.715625       Train: 0.953571428571\n",
      "Round: 104   Test: 0.724479166667 Train: 0.952040816327\n",
      "Round: 105   Test: 0.720833333333 Train: 0.950340136054\n",
      "Round: 106   Test: 0.714583333333 Train: 0.948979591837\n",
      "Round: 107   Test: 0.7140625      Train: 0.948979591837\n",
      "Round: 108   Test: 0.726041666667 Train: 0.953911564626\n",
      "Round: 109   Test: 0.71875        Train: 0.955102040816\n",
      "Round: 110   Test: 0.722916666667 Train: 0.951700680272\n",
      "Round: 111   Test: 0.724479166667 Train: 0.949489795918\n",
      "Round: 112   Test: 0.713020833333 Train: 0.951870748299\n",
      "Round: 113   Test: 0.723958333333 Train: 0.95119047619\n",
      "Round: 114   Test: 0.7203125      Train: 0.950340136054\n",
      "Round: 115   Test: 0.717708333333 Train: 0.951020408163\n",
      "Round: 116   Test: 0.7140625      Train: 0.95    \n",
      "Round: 117   Test: 0.719791666667 Train: 0.952721088435\n",
      "Round: 118   Test: 0.721875       Train: 0.95425170068\n",
      "Round: 119   Test: 0.7234375      Train: 0.95306122449\n",
      "Round: 120   Test: 0.715625       Train: 0.952380952381\n",
      "Round: 121   Test: 0.7203125      Train: 0.951020408163\n",
      "Round: 122   Test: 0.718229166667 Train: 0.952721088435\n",
      "Round: 123   Test: 0.725          Train: 0.949319727891\n",
      "Round: 124   Test: 0.7171875      Train: 0.952551020408\n",
      "Round: 125   Test: 0.727604166667 Train: 0.951870748299\n",
      "Round: 126   Test: 0.724479166667 Train: 0.95119047619\n",
      "Round: 127   Test: 0.719270833333 Train: 0.952380952381\n",
      "Round: 128   Test: 0.716666666667 Train: 0.952040816327\n",
      "Round: 129   Test: 0.7203125      Train: 0.955612244898\n",
      "Round: 130   Test: 0.719270833333 Train: 0.950850340136\n",
      "Round: 131   Test: 0.7171875      Train: 0.95    \n",
      "Round: 132   Test: 0.725          Train: 0.952380952381\n",
      "Round: 133   Test: 0.715104166667 Train: 0.951020408163\n",
      "Round: 134   Test: 0.71875        Train: 0.952380952381\n",
      "Round: 135   Test: 0.709895833333 Train: 0.950680272109\n",
      "Round: 136   Test: 0.724479166667 Train: 0.951870748299\n",
      "Round: 137   Test: 0.717708333333 Train: 0.949659863946\n",
      "Round: 138   Test: 0.716145833333 Train: 0.95425170068\n",
      "Round: 139   Test: 0.717708333333 Train: 0.95119047619\n",
      "Round: 140   Test: 0.7203125      Train: 0.951700680272\n",
      "Round: 141   Test: 0.7125         Train: 0.952210884354\n",
      "Round: 142   Test: 0.719270833333 Train: 0.951020408163\n",
      "Round: 143   Test: 0.7171875      Train: 0.955272108844\n",
      "Round: 144   Test: 0.719270833333 Train: 0.950850340136\n",
      "Round: 145   Test: 0.713020833333 Train: 0.95119047619\n",
      "Round: 146   Test: 0.730729166667 Train: 0.949149659864\n",
      "Round: 147   Test: 0.714583333333 Train: 0.951530612245\n",
      "Round: 148   Test: 0.721354166667 Train: 0.951870748299\n",
      "Round: 149   Test: 0.722916666667 Train: 0.953231292517\n",
      "Round: 150   Test: 0.721875       Train: 0.950680272109\n",
      "Round: 151   Test: 0.719791666667 Train: 0.947619047619\n",
      "Round: 152   Test: 0.71875        Train: 0.951700680272\n",
      "Round: 153   Test: 0.7203125      Train: 0.955272108844\n",
      "Round: 154   Test: 0.713541666667 Train: 0.950680272109\n",
      "Round: 155   Test: 0.704166666667 Train: 0.951870748299\n",
      "Round: 156   Test: 0.725          Train: 0.951700680272\n",
      "Round: 157   Test: 0.7171875      Train: 0.948979591837\n",
      "Round: 158   Test: 0.716145833333 Train: 0.952721088435\n",
      "Round: 159   Test: 0.722395833333 Train: 0.951870748299\n",
      "Round: 160   Test: 0.714583333333 Train: 0.951870748299\n",
      "Round: 161   Test: 0.718229166667 Train: 0.95    \n",
      "Round: 162   Test: 0.720833333333 Train: 0.951700680272\n",
      "Round: 163   Test: 0.7140625      Train: 0.952210884354\n",
      "Round: 164   Test: 0.716666666667 Train: 0.95119047619\n",
      "Round: 165   Test: 0.722916666667 Train: 0.95306122449\n",
      "Round: 166   Test: 0.717708333333 Train: 0.948639455782\n",
      "Round: 167   Test: 0.716666666667 Train: 0.953571428571\n",
      "Round: 168   Test: 0.722916666667 Train: 0.952040816327\n",
      "Round: 169   Test: 0.716666666667 Train: 0.953741496599\n",
      "Round: 170   Test: 0.715625       Train: 0.952380952381\n",
      "Round: 171   Test: 0.721354166667 Train: 0.951530612245\n",
      "Round: 172   Test: 0.7234375      Train: 0.954591836735\n",
      "Round: 173   Test: 0.716145833333 Train: 0.955782312925\n",
      "Round: 174   Test: 0.713020833333 Train: 0.953571428571\n",
      "Round: 175   Test: 0.7234375      Train: 0.950340136054\n",
      "Round: 176   Test: 0.730208333333 Train: 0.953571428571\n",
      "Round: 177   Test: 0.716666666667 Train: 0.951020408163\n",
      "Round: 178   Test: 0.713020833333 Train: 0.953231292517\n",
      "Round: 179   Test: 0.711979166667 Train: 0.955102040816\n",
      "Round: 180   Test: 0.7234375      Train: 0.952721088435\n",
      "Round: 181   Test: 0.715625       Train: 0.953571428571\n",
      "Round: 182   Test: 0.716666666667 Train: 0.955272108844\n",
      "Round: 183   Test: 0.728125       Train: 0.951870748299\n",
      "Round: 184   Test: 0.728125       Train: 0.951700680272\n",
      "Round: 185   Test: 0.71875        Train: 0.95119047619\n",
      "Round: 186   Test: 0.720833333333 Train: 0.952721088435\n",
      "Round: 187   Test: 0.7234375      Train: 0.95306122449\n",
      "Round: 188   Test: 0.7171875      Train: 0.95306122449\n",
      "Round: 189   Test: 0.720833333333 Train: 0.952551020408\n",
      "Round: 190   Test: 0.7171875      Train: 0.948639455782\n",
      "Round: 191   Test: 0.718229166667 Train: 0.949149659864\n",
      "Round: 192   Test: 0.718229166667 Train: 0.949319727891\n",
      "Round: 193   Test: 0.7171875      Train: 0.951360544218\n",
      "Round: 194   Test: 0.722916666667 Train: 0.95119047619\n",
      "Round: 195   Test: 0.718229166667 Train: 0.955272108844\n",
      "Round: 196   Test: 0.716145833333 Train: 0.952210884354\n",
      "Round: 197   Test: 0.713541666667 Train: 0.953231292517\n",
      "Round: 198   Test: 0.707291666667 Train: 0.950510204082\n",
      "Round: 199   Test: 0.7234375      Train: 0.95119047619\n",
      "Round: 200   Test: 0.7203125      Train: 0.950340136054\n",
      "Round: 201   Test: 0.714583333333 Train: 0.954421768707\n",
      "Round: 202   Test: 0.722916666667 Train: 0.950510204082\n",
      "Round: 203   Test: 0.716666666667 Train: 0.952891156463\n",
      "Round: 204   Test: 0.720833333333 Train: 0.955272108844\n",
      "Round: 205   Test: 0.714583333333 Train: 0.952040816327\n",
      "Round: 206   Test: 0.71875        Train: 0.954591836735\n",
      "Round: 207   Test: 0.7203125      Train: 0.950340136054\n",
      "Round: 208   Test: 0.719270833333 Train: 0.952551020408\n",
      "Round: 209   Test: 0.715104166667 Train: 0.951020408163\n",
      "Round: 210   Test: 0.716666666667 Train: 0.953741496599\n",
      "Round: 211   Test: 0.721875       Train: 0.950680272109\n",
      "Round: 212   Test: 0.726041666667 Train: 0.955952380952\n",
      "Round: 213   Test: 0.718229166667 Train: 0.95425170068\n",
      "Round: 214   Test: 0.717708333333 Train: 0.951700680272\n",
      "Round: 215   Test: 0.714583333333 Train: 0.952721088435\n",
      "Round: 216   Test: 0.724479166667 Train: 0.951360544218\n",
      "Round: 217   Test: 0.7140625      Train: 0.953571428571\n",
      "Round: 218   Test: 0.723958333333 Train: 0.951530612245\n",
      "Round: 219   Test: 0.716145833333 Train: 0.951700680272\n",
      "Round: 220   Test: 0.721354166667 Train: 0.954591836735\n",
      "Round: 221   Test: 0.721354166667 Train: 0.952551020408\n",
      "Round: 222   Test: 0.714583333333 Train: 0.952210884354\n",
      "Round: 223   Test: 0.727604166667 Train: 0.951870748299\n",
      "Round: 224   Test: 0.725          Train: 0.950510204082\n",
      "Round: 225   Test: 0.7203125      Train: 0.950850340136\n",
      "Round: 226   Test: 0.711979166667 Train: 0.95425170068\n",
      "Round: 227   Test: 0.716145833333 Train: 0.95119047619\n",
      "Round: 228   Test: 0.7171875      Train: 0.952891156463\n",
      "Round: 229   Test: 0.7203125      Train: 0.95119047619\n",
      "Round: 230   Test: 0.7171875      Train: 0.95119047619\n",
      "Round: 231   Test: 0.716145833333 Train: 0.951870748299\n",
      "Round: 232   Test: 0.722395833333 Train: 0.953231292517\n",
      "Round: 233   Test: 0.718229166667 Train: 0.95119047619\n",
      "Round: 234   Test: 0.7125         Train: 0.953911564626\n",
      "Round: 235   Test: 0.722916666667 Train: 0.949829931973\n",
      "Round: 236   Test: 0.71875        Train: 0.953401360544\n",
      "Round: 237   Test: 0.714583333333 Train: 0.948979591837\n",
      "Round: 238   Test: 0.720833333333 Train: 0.950680272109\n",
      "Round: 239   Test: 0.716666666667 Train: 0.953231292517\n",
      "Round: 240   Test: 0.719791666667 Train: 0.953571428571\n",
      "Round: 241   Test: 0.7203125      Train: 0.95119047619\n",
      "Round: 242   Test: 0.71875        Train: 0.953401360544\n",
      "Round: 243   Test: 0.713541666667 Train: 0.951870748299\n",
      "Round: 244   Test: 0.717708333333 Train: 0.950170068027\n",
      "Round: 245   Test: 0.7109375      Train: 0.951020408163\n",
      "Round: 246   Test: 0.717708333333 Train: 0.953231292517\n",
      "Round: 247   Test: 0.715625       Train: 0.950680272109\n",
      "Round: 248   Test: 0.7171875      Train: 0.954081632653\n",
      "Round: 249   Test: 0.719270833333 Train: 0.950170068027\n",
      "Round: 250   Test: 0.718229166667 Train: 0.955952380952\n",
      "Round: 251   Test: 0.713541666667 Train: 0.954591836735\n",
      "Round: 252   Test: 0.703645833333 Train: 0.952551020408\n",
      "Round: 253   Test: 0.713541666667 Train: 0.954081632653\n",
      "Round: 254   Test: 0.711458333333 Train: 0.95119047619\n",
      "Round: 255   Test: 0.717708333333 Train: 0.950680272109\n",
      "Round: 256   Test: 0.723958333333 Train: 0.955272108844\n",
      "Round: 257   Test: 0.7171875      Train: 0.952551020408\n",
      "Round: 258   Test: 0.715104166667 Train: 0.954591836735\n",
      "Round: 259   Test: 0.717708333333 Train: 0.951530612245\n",
      "Round: 260   Test: 0.718229166667 Train: 0.952891156463\n",
      "Round: 261   Test: 0.718229166667 Train: 0.949659863946\n",
      "Round: 262   Test: 0.713020833333 Train: 0.952210884354\n",
      "Round: 263   Test: 0.7171875      Train: 0.952210884354\n",
      "Round: 264   Test: 0.710416666667 Train: 0.953231292517\n",
      "Round: 265   Test: 0.716145833333 Train: 0.95306122449\n",
      "Round: 266   Test: 0.717708333333 Train: 0.952891156463\n",
      "Round: 267   Test: 0.721875       Train: 0.951700680272\n",
      "Round: 268   Test: 0.713541666667 Train: 0.955272108844\n",
      "Round: 269   Test: 0.718229166667 Train: 0.95306122449\n",
      "Round: 270   Test: 0.722916666667 Train: 0.954081632653\n",
      "Round: 271   Test: 0.717708333333 Train: 0.952551020408\n",
      "Round: 272   Test: 0.714583333333 Train: 0.95306122449\n",
      "Round: 273   Test: 0.715104166667 Train: 0.950170068027\n",
      "Round: 274   Test: 0.71875        Train: 0.951360544218\n",
      "Round: 275   Test: 0.7140625      Train: 0.952210884354\n",
      "Round: 276   Test: 0.711979166667 Train: 0.952040816327\n",
      "Round: 277   Test: 0.713020833333 Train: 0.952891156463\n",
      "Round: 278   Test: 0.719270833333 Train: 0.952210884354\n",
      "Round: 279   Test: 0.709895833333 Train: 0.95119047619\n",
      "Round: 280   Test: 0.721875       Train: 0.951360544218\n",
      "Round: 281   Test: 0.721875       Train: 0.951530612245\n",
      "Round: 282   Test: 0.715104166667 Train: 0.954591836735\n",
      "Round: 283   Test: 0.715104166667 Train: 0.952380952381\n",
      "Round: 284   Test: 0.718229166667 Train: 0.954081632653\n",
      "Round: 285   Test: 0.717708333333 Train: 0.950340136054\n",
      "Round: 286   Test: 0.726041666667 Train: 0.952721088435\n",
      "Round: 287   Test: 0.713541666667 Train: 0.95119047619\n",
      "Round: 288   Test: 0.706770833333 Train: 0.951870748299\n",
      "Round: 289   Test: 0.716145833333 Train: 0.954761904762\n",
      "Round: 290   Test: 0.714583333333 Train: 0.952040816327\n",
      "Round: 291   Test: 0.719270833333 Train: 0.951020408163\n",
      "Round: 292   Test: 0.716145833333 Train: 0.952040816327\n",
      "Round: 293   Test: 0.71875        Train: 0.95306122449\n",
      "Round: 294   Test: 0.719270833333 Train: 0.954081632653\n",
      "Round: 295   Test: 0.713541666667 Train: 0.953231292517\n",
      "Round: 296   Test: 0.715104166667 Train: 0.952551020408\n",
      "Round: 297   Test: 0.717708333333 Train: 0.953741496599\n",
      "Round: 298   Test: 0.7125         Train: 0.95425170068\n",
      "Round: 299   Test: 0.714583333333 Train: 0.953231292517\n",
      "Round: 300   Test: 0.7125         Train: 0.950510204082\n",
      "Round: 301   Test: 0.713020833333 Train: 0.952721088435\n",
      "Round: 302   Test: 0.725520833333 Train: 0.952210884354\n",
      "Round: 303   Test: 0.709895833333 Train: 0.951530612245\n",
      "Round: 304   Test: 0.713541666667 Train: 0.950340136054\n",
      "Round: 305   Test: 0.719791666667 Train: 0.952551020408\n",
      "Round: 306   Test: 0.7171875      Train: 0.949149659864\n",
      "Round: 307   Test: 0.708333333333 Train: 0.950850340136\n",
      "Round: 308   Test: 0.711979166667 Train: 0.955952380952\n",
      "Round: 309   Test: 0.719791666667 Train: 0.954931972789\n",
      "Round: 310   Test: 0.70625        Train: 0.951530612245\n",
      "Round: 311   Test: 0.722916666667 Train: 0.952891156463\n",
      "Round: 312   Test: 0.7171875      Train: 0.951530612245\n",
      "Round: 313   Test: 0.719270833333 Train: 0.952040816327\n",
      "Round: 314   Test: 0.7171875      Train: 0.952380952381\n",
      "Round: 315   Test: 0.7171875      Train: 0.952721088435\n",
      "Round: 316   Test: 0.720833333333 Train: 0.949149659864\n",
      "Round: 317   Test: 0.711979166667 Train: 0.954591836735\n",
      "Round: 318   Test: 0.720833333333 Train: 0.952551020408\n",
      "Round: 319   Test: 0.718229166667 Train: 0.95425170068\n",
      "Round: 320   Test: 0.718229166667 Train: 0.950510204082\n",
      "Round: 321   Test: 0.7140625      Train: 0.955272108844\n",
      "Round: 322   Test: 0.713020833333 Train: 0.953911564626\n",
      "Round: 323   Test: 0.711979166667 Train: 0.952551020408\n",
      "Round: 324   Test: 0.709895833333 Train: 0.953911564626\n",
      "Round: 325   Test: 0.722916666667 Train: 0.95119047619\n",
      "Round: 326   Test: 0.717708333333 Train: 0.951870748299\n",
      "Round: 327   Test: 0.717708333333 Train: 0.95119047619\n",
      "Round: 328   Test: 0.7140625      Train: 0.952551020408\n",
      "Round: 329   Test: 0.711458333333 Train: 0.953401360544\n",
      "Round: 330   Test: 0.722395833333 Train: 0.951700680272\n",
      "Round: 331   Test: 0.716145833333 Train: 0.953401360544\n",
      "Round: 332   Test: 0.724479166667 Train: 0.950850340136\n",
      "Round: 333   Test: 0.717708333333 Train: 0.951870748299\n",
      "Round: 334   Test: 0.708333333333 Train: 0.952380952381\n",
      "Round: 335   Test: 0.716666666667 Train: 0.954421768707\n",
      "Round: 336   Test: 0.716145833333 Train: 0.95425170068\n",
      "Round: 337   Test: 0.721875       Train: 0.952721088435\n",
      "Round: 338   Test: 0.715625       Train: 0.948639455782\n",
      "Round: 339   Test: 0.7203125      Train: 0.951360544218\n",
      "Round: 340   Test: 0.714583333333 Train: 0.952891156463\n",
      "Round: 341   Test: 0.722395833333 Train: 0.952891156463\n",
      "Round: 342   Test: 0.714583333333 Train: 0.953231292517\n",
      "Round: 343   Test: 0.718229166667 Train: 0.952721088435\n",
      "Round: 344   Test: 0.7078125      Train: 0.951360544218\n",
      "Round: 345   Test: 0.727083333333 Train: 0.950510204082\n",
      "Round: 346   Test: 0.715104166667 Train: 0.954421768707\n",
      "Round: 347   Test: 0.7140625      Train: 0.949829931973\n",
      "Round: 348   Test: 0.715625       Train: 0.952380952381\n",
      "Round: 349   Test: 0.715625       Train: 0.952380952381\n",
      "Round: 350   Test: 0.716666666667 Train: 0.954421768707\n",
      "Round: 351   Test: 0.7109375      Train: 0.954591836735\n",
      "Round: 352   Test: 0.7109375      Train: 0.952380952381\n",
      "Round: 353   Test: 0.721354166667 Train: 0.951700680272\n",
      "Round: 354   Test: 0.716666666667 Train: 0.954081632653\n",
      "Round: 355   Test: 0.716145833333 Train: 0.95425170068\n",
      "Round: 356   Test: 0.721875       Train: 0.956292517007\n",
      "Round: 357   Test: 0.713541666667 Train: 0.952551020408\n",
      "Round: 358   Test: 0.717708333333 Train: 0.953401360544\n",
      "Round: 359   Test: 0.7171875      Train: 0.952891156463\n",
      "Round: 360   Test: 0.715104166667 Train: 0.953741496599\n",
      "Round: 361   Test: 0.71875        Train: 0.951700680272\n",
      "Round: 362   Test: 0.7203125      Train: 0.950850340136\n",
      "Round: 363   Test: 0.721354166667 Train: 0.953231292517\n",
      "Round: 364   Test: 0.709375       Train: 0.954931972789\n",
      "Round: 365   Test: 0.7140625      Train: 0.956462585034\n",
      "Round: 366   Test: 0.711979166667 Train: 0.953401360544\n",
      "Round: 367   Test: 0.71875        Train: 0.953741496599\n",
      "Round: 368   Test: 0.722395833333 Train: 0.952380952381\n",
      "Round: 369   Test: 0.723958333333 Train: 0.95425170068\n",
      "Round: 370   Test: 0.720833333333 Train: 0.954761904762\n",
      "Round: 371   Test: 0.7140625      Train: 0.955952380952\n",
      "Round: 372   Test: 0.7171875      Train: 0.952040816327\n",
      "Round: 373   Test: 0.717708333333 Train: 0.951360544218\n",
      "Round: 374   Test: 0.719270833333 Train: 0.953571428571\n",
      "Round: 375   Test: 0.7171875      Train: 0.953741496599\n",
      "Round: 376   Test: 0.705208333333 Train: 0.955952380952\n",
      "Round: 377   Test: 0.7078125      Train: 0.956462585034\n",
      "Round: 378   Test: 0.717708333333 Train: 0.950680272109\n",
      "Round: 379   Test: 0.7203125      Train: 0.954761904762\n",
      "Round: 380   Test: 0.713541666667 Train: 0.951700680272\n",
      "Round: 381   Test: 0.716145833333 Train: 0.951700680272\n",
      "Round: 382   Test: 0.715104166667 Train: 0.952210884354\n",
      "Round: 383   Test: 0.711458333333 Train: 0.952551020408\n",
      "Round: 384   Test: 0.723958333333 Train: 0.952891156463\n",
      "Round: 385   Test: 0.715625       Train: 0.952210884354\n",
      "Round: 386   Test: 0.7140625      Train: 0.953571428571\n",
      "Round: 387   Test: 0.719791666667 Train: 0.955272108844\n",
      "Round: 388   Test: 0.722916666667 Train: 0.95    \n",
      "Round: 389   Test: 0.721354166667 Train: 0.953911564626\n",
      "Round: 390   Test: 0.717708333333 Train: 0.955272108844\n",
      "Round: 391   Test: 0.721354166667 Train: 0.955272108844\n",
      "Round: 392   Test: 0.71875        Train: 0.955102040816\n",
      "Round: 393   Test: 0.715104166667 Train: 0.95306122449\n",
      "Round: 394   Test: 0.715104166667 Train: 0.95119047619\n",
      "Round: 395   Test: 0.711979166667 Train: 0.954421768707\n",
      "Round: 396   Test: 0.715104166667 Train: 0.952210884354\n",
      "Round: 397   Test: 0.71875        Train: 0.954421768707\n",
      "Round: 398   Test: 0.722916666667 Train: 0.949149659864\n",
      "Round: 399   Test: 0.716666666667 Train: 0.95119047619\n",
      "Round: 400   Test: 0.713020833333 Train: 0.952210884354\n",
      "Round: 401   Test: 0.716666666667 Train: 0.954421768707\n",
      "Round: 402   Test: 0.71875        Train: 0.954081632653\n",
      "Round: 403   Test: 0.7125         Train: 0.953741496599\n",
      "Round: 404   Test: 0.716145833333 Train: 0.954591836735\n",
      "Round: 405   Test: 0.714583333333 Train: 0.950340136054\n",
      "Round: 406   Test: 0.713020833333 Train: 0.951530612245\n",
      "Round: 407   Test: 0.716145833333 Train: 0.952040816327\n",
      "Round: 408   Test: 0.711979166667 Train: 0.95612244898\n",
      "Round: 409   Test: 0.718229166667 Train: 0.951020408163\n",
      "Round: 410   Test: 0.715104166667 Train: 0.954421768707\n",
      "Round: 411   Test: 0.716666666667 Train: 0.952380952381\n",
      "Round: 412   Test: 0.718229166667 Train: 0.953571428571\n",
      "Round: 413   Test: 0.716666666667 Train: 0.952721088435\n",
      "Round: 414   Test: 0.716666666667 Train: 0.953571428571\n",
      "Round: 415   Test: 0.720833333333 Train: 0.952210884354\n",
      "Round: 416   Test: 0.716666666667 Train: 0.95425170068\n",
      "Round: 417   Test: 0.719270833333 Train: 0.950170068027\n",
      "Round: 418   Test: 0.713020833333 Train: 0.955102040816\n",
      "Round: 419   Test: 0.713541666667 Train: 0.95306122449\n",
      "Round: 420   Test: 0.722916666667 Train: 0.954761904762\n",
      "Round: 421   Test: 0.71875        Train: 0.952380952381\n",
      "Round: 422   Test: 0.7109375      Train: 0.956632653061\n",
      "Round: 423   Test: 0.711458333333 Train: 0.951530612245\n",
      "Round: 424   Test: 0.714583333333 Train: 0.95    \n",
      "Round: 425   Test: 0.719270833333 Train: 0.95119047619\n",
      "Round: 426   Test: 0.7171875      Train: 0.952040816327\n",
      "Round: 427   Test: 0.721354166667 Train: 0.954761904762\n",
      "Round: 428   Test: 0.717708333333 Train: 0.951700680272\n",
      "Round: 429   Test: 0.709375       Train: 0.953231292517\n",
      "Round: 430   Test: 0.719791666667 Train: 0.953231292517\n",
      "Round: 431   Test: 0.713541666667 Train: 0.95306122449\n",
      "Round: 432   Test: 0.7203125      Train: 0.952551020408\n",
      "Round: 433   Test: 0.70625        Train: 0.954591836735\n",
      "Round: 434   Test: 0.706770833333 Train: 0.952040816327\n",
      "Round: 435   Test: 0.716666666667 Train: 0.955102040816\n",
      "Round: 436   Test: 0.721875       Train: 0.95425170068\n",
      "Round: 437   Test: 0.713541666667 Train: 0.950510204082\n",
      "Round: 438   Test: 0.711979166667 Train: 0.956292517007\n",
      "Round: 439   Test: 0.713541666667 Train: 0.955442176871\n",
      "Round: 440   Test: 0.70625        Train: 0.951360544218\n",
      "Round: 441   Test: 0.721354166667 Train: 0.952721088435\n",
      "Round: 442   Test: 0.711458333333 Train: 0.951700680272\n",
      "Round: 443   Test: 0.720833333333 Train: 0.951700680272\n",
      "Round: 444   Test: 0.71875        Train: 0.951530612245\n",
      "Round: 445   Test: 0.713020833333 Train: 0.95    \n",
      "Round: 446   Test: 0.7140625      Train: 0.952210884354\n",
      "Round: 447   Test: 0.717708333333 Train: 0.951870748299\n",
      "Round: 448   Test: 0.715625       Train: 0.953741496599\n",
      "Round: 449   Test: 0.711979166667 Train: 0.954591836735\n",
      "Round: 450   Test: 0.715104166667 Train: 0.952380952381\n",
      "Round: 451   Test: 0.722395833333 Train: 0.953401360544\n",
      "Round: 452   Test: 0.718229166667 Train: 0.955442176871\n",
      "Round: 453   Test: 0.714583333333 Train: 0.952891156463\n",
      "Round: 454   Test: 0.722395833333 Train: 0.953911564626\n",
      "Round: 455   Test: 0.705729166667 Train: 0.951020408163\n",
      "Round: 456   Test: 0.71875        Train: 0.953911564626\n",
      "Round: 457   Test: 0.716666666667 Train: 0.954081632653\n",
      "Round: 458   Test: 0.709375       Train: 0.953571428571\n",
      "Round: 459   Test: 0.715625       Train: 0.952721088435\n",
      "Round: 460   Test: 0.716145833333 Train: 0.950170068027\n",
      "Round: 461   Test: 0.722395833333 Train: 0.95306122449\n",
      "Round: 462   Test: 0.719270833333 Train: 0.951360544218\n",
      "Round: 463   Test: 0.721354166667 Train: 0.95425170068\n",
      "Round: 464   Test: 0.715625       Train: 0.953911564626\n",
      "Round: 465   Test: 0.719791666667 Train: 0.950680272109\n",
      "Round: 466   Test: 0.710416666667 Train: 0.955782312925\n",
      "Round: 467   Test: 0.717708333333 Train: 0.95612244898\n",
      "Round: 468   Test: 0.717708333333 Train: 0.952380952381\n",
      "Round: 469   Test: 0.716145833333 Train: 0.954591836735\n",
      "Round: 470   Test: 0.711458333333 Train: 0.950340136054\n",
      "Round: 471   Test: 0.7265625      Train: 0.952891156463\n",
      "Round: 472   Test: 0.715104166667 Train: 0.952551020408\n",
      "Round: 473   Test: 0.722395833333 Train: 0.953741496599\n",
      "Round: 474   Test: 0.7203125      Train: 0.953401360544\n",
      "Round: 475   Test: 0.717708333333 Train: 0.952040816327\n",
      "Round: 476   Test: 0.719270833333 Train: 0.954081632653\n",
      "Round: 477   Test: 0.715625       Train: 0.953911564626\n",
      "Round: 478   Test: 0.727083333333 Train: 0.956802721088\n",
      "Round: 479   Test: 0.716145833333 Train: 0.952210884354\n",
      "Round: 480   Test: 0.713020833333 Train: 0.953571428571\n",
      "Round: 481   Test: 0.722395833333 Train: 0.953741496599\n",
      "Round: 482   Test: 0.715104166667 Train: 0.95306122449\n",
      "Round: 483   Test: 0.707291666667 Train: 0.951360544218\n",
      "Round: 484   Test: 0.713541666667 Train: 0.953571428571\n",
      "Round: 485   Test: 0.7109375      Train: 0.954931972789\n",
      "Round: 486   Test: 0.7125         Train: 0.955272108844\n",
      "Round: 487   Test: 0.7            Train: 0.953741496599\n",
      "Round: 488   Test: 0.7109375      Train: 0.95306122449\n",
      "Round: 489   Test: 0.720833333333 Train: 0.954081632653\n",
      "Round: 490   Test: 0.7140625      Train: 0.954081632653\n",
      "Round: 491   Test: 0.709895833333 Train: 0.953571428571\n",
      "Round: 492   Test: 0.70625        Train: 0.956972789116\n",
      "Round: 493   Test: 0.715104166667 Train: 0.954931972789\n",
      "Round: 494   Test: 0.71875        Train: 0.952721088435\n",
      "Round: 495   Test: 0.717708333333 Train: 0.952891156463\n",
      "Round: 496   Test: 0.7171875      Train: 0.953741496599\n",
      "Round: 497   Test: 0.7125         Train: 0.953571428571\n",
      "Round: 498   Test: 0.716145833333 Train: 0.95306122449\n",
      "Round: 499   Test: 0.715104166667 Train: 0.954761904762\n",
      "Round: 500   Test: 0.708854166667 Train: 0.951020408163\n",
      "Round: 501   Test: 0.716666666667 Train: 0.953401360544\n",
      "Round: 502   Test: 0.7125         Train: 0.955782312925\n",
      "Round: 503   Test: 0.709895833333 Train: 0.954421768707\n",
      "\n",
      "CPU times: user 45min 56s, sys: 2min 9s, total: 48min 6s\n",
      "Wall time: 28min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\"\"\" glorot 4-layer: batch, batch, batch \n",
    "    random indexing, ELU                \"\"\"\n",
    "\n",
    "# batch normalization code adapted from \n",
    "# https://groups.google.com/forum/#!topic/theano-users/dMV6aabL1Ds \n",
    "\n",
    "\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "from theano.tensor.nnet.bn import batch_normalization\n",
    "import numpy as np\n",
    "\n",
    "srng = RandomStreams()\n",
    "\n",
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def init_weights(shape):\n",
    "    (h, w) = shape\n",
    "    # Glorot normalization - last factor depends on non-linearity\n",
    "    # 0.25 for sigmoid and 0.1 for softmax, 1.0 for tanh or Relu\n",
    "    normalizer = 2.0 * np.sqrt(6) / np.sqrt(h + w) * 1.0\n",
    "    return theano.shared(floatX((np.random.random_sample(shape) - 0.5) * normalizer))\n",
    "\n",
    "def rectify(X, alpha=0.01):\n",
    "#     return T.maximum(X, 0.)\n",
    "#    return T.maximum(X, 0.1*X)  #leaky rectifier\n",
    "     return T.switch(X > 0, X, alpha * (T.exp(X) - 1)) # ELU\n",
    "\n",
    "def softmax(X):\n",
    "    e_x = T.exp(X - X.max(axis=1).dimshuffle(0, 'x'))\n",
    "    return e_x / e_x.sum(axis=1).dimshuffle(0, 'x')\n",
    "\n",
    "def RMSprop(cost, params, lr=0.001, rho=0.99, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        acc = theano.shared(p.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
    "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
    "        g = g / gradient_scaling\n",
    "        updates.append((acc, acc_new))\n",
    "        updates.append((p, p - lr * g))\n",
    "    return updates\n",
    "\n",
    "\n",
    "def model(X, w_h, b_h, g_h, bb_h, w_h2, b_h2, g_h2, bb_h2, w_o, b_ho, g_ho, bb_ho):\n",
    "    X = T.dot(X, w_h) + b_h\n",
    "    X = batch_normalization(X, gamma= g_h, beta= bb_h, \n",
    "                            mean= X.mean((0,), keepdims=True),\n",
    "                            std= T.ones_like(X.var((0,), keepdims = True)), \n",
    "                            mode='high_mem')    \n",
    "    h = rectify(X)\n",
    "\n",
    "    h  = T.dot(h, w_h2) + b_h2\n",
    "    h = batch_normalization(h, gamma= g_h2, beta= bb_h2, \n",
    "                            mean= h.mean((0,), keepdims=True),\n",
    "                            std= T.ones_like(h.var((0,), keepdims = True)), \n",
    "                            mode='high_mem')       \n",
    "    h2 = rectify(h)\n",
    "\n",
    "    h2 = T.dot(h2, w_o) + b_ho\n",
    "    h2 = batch_normalization(h2, gamma= g_ho, beta= bb_ho, \n",
    "                            mean= h2.mean((0,), keepdims=True),\n",
    "                            std= T.ones_like(h2.var((0,), keepdims = True)), \n",
    "                            mode='high_mem')   \n",
    "    py_x = softmax(h2)\n",
    "    return h, h2, py_x\n",
    "\n",
    "\n",
    "X = T.fmatrix()\n",
    "Y = T.fmatrix()\n",
    "\n",
    "batch_size = 60\n",
    "\n",
    "h1_size = 600\n",
    "h2_size = 550\n",
    "\n",
    "w_h = init_weights((len(vectorizer.vocabulary_), h1_size))\n",
    "b_h = theano.shared(floatX(np.zeros(h1_size)))\n",
    "g_h = theano.shared(floatX(np.ones((h1_size))))\n",
    "bb_h = theano.shared(floatX(np.zeros((h1_size))))\n",
    "\n",
    "w_h2 = init_weights((h1_size, h2_size))\n",
    "b_h2 = theano.shared(floatX(np.zeros(h2_size)))\n",
    "g_h2 = theano.shared(floatX(np.ones((h2_size))))\n",
    "bb_h2 = theano.shared(floatX(np.zeros((h2_size))))\n",
    "\n",
    "w_o = init_weights((h2_size, yTest.shape[1]))\n",
    "b_ho = theano.shared(floatX(np.zeros(yTest.shape[1])))\n",
    "g_ho = theano.shared(floatX(np.ones((yTest.shape[1]))))\n",
    "bb_ho = theano.shared(floatX(np.zeros((yTest.shape[1]))))\n",
    "\n",
    "noise_h, noise_h2, noise_py_x = model(X, w_h, b_h, g_h, bb_h, \n",
    "                                      w_h2, b_h2, g_h2, bb_h2, \n",
    "                                      w_o, b_ho, g_ho, bb_ho)\n",
    "\n",
    "h, h2, py_x = model(X, w_h, b_h, g_h, bb_h, \n",
    "                    w_h2, b_h2, g_h2, bb_h2, \n",
    "                    w_o, b_ho, g_ho, bb_ho)\n",
    "\n",
    "y_x = T.argmax(py_x, axis=1)\n",
    "\n",
    "\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(noise_py_x, Y))\n",
    "params = [w_h, b_h, g_h, bb_h, w_h2, b_h2, g_h2, bb_h2, w_o, b_ho, g_ho, bb_ho]\n",
    "updates = RMSprop(cost, params, lr=0.0001)\n",
    "\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "predict = theano.function(inputs=[X], outputs=y_x, allow_input_downcast=True)\n",
    "\n",
    "\n",
    "for i in range(504):\n",
    "\n",
    "    for start, end in zip(range(0, len(xTrain), batch_size), range(batch_size, len(xTrain), batch_size)):\n",
    "        cost = train(xTrain[start:end], yTrain[start:end])\n",
    "        \n",
    "    xTrain, yTrain = shuffle(xTrain, yTrain)\n",
    "    xTest, yTest   = shuffle(xTest, yTest)\n",
    "\n",
    "    trr, tr = [], []\n",
    "    for start, end in zip(range(0, len(xTrain), batch_size), range(batch_size, len(xTrain), batch_size)):        \n",
    "        trr += [np.argmax(yTrain[start:end], axis=1) == predict(xTrain[start:end])]\n",
    "\n",
    "    for start, end in zip(range(0, len(xTest), batch_size), range(batch_size, len(xTest), batch_size)):\n",
    "        tr += [np.argmax(yTest[start:end], axis=1) == predict(xTest[start:end])]\n",
    "        \n",
    "    if i == 80:\n",
    "        cost = T.mean(T.nnet.categorical_crossentropy(noise_py_x, Y))\n",
    "        params = [w_h, b_h, g_h, bb_h, w_h2, b_h2, g_h2, bb_h2, w_o, b_ho, g_ho, bb_ho]\n",
    "        updates = RMSprop(cost, params, lr=0.00001)\n",
    "\n",
    "        train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "        predict = theano.function(inputs=[X], outputs=y_x, allow_input_downcast=True)\n",
    "\n",
    "    print \"Round: %-5s Test: %-14s Train: %-8s\" % (i, np.mean(tr), np.mean(trr))\n",
    "    \n",
    "print\n",
    "\n",
    "# for i in range(34):\n",
    "#     for start, end in zip(range(0, len(xTrain), batch_size), range(batch_size, len(xTrain), batch_size)):\n",
    "#         index = np.random.choice(xTrain.shape[0], batch_size, replace=False)\n",
    "#         cost = train(xTrain[index], yTrain[index])\n",
    "\n",
    "#     tr = np.mean(np.argmax(yTest, axis=1) == predict(xTest))\n",
    "#     trr =  np.mean(np.argmax(yTrain, axis=1) == predict(xTrain))\n",
    "#     print 'Round:', i,\" Test:\", tr, ' Train:', trr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
