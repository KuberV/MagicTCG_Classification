{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split, KFold, cross_val_score\n",
    "import sklearn.metrics as sk\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({u'Black': 1576,\n",
       "         u'Blue': 1573,\n",
       "         u'Green': 1566,\n",
       "         u'Red': 1575,\n",
       "         u'White': 1584})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modern = pd.read_pickle('data/5color_modern_no_name_hardmode.pkl')\n",
    "Counter(modern.colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all the data munging the classes are still amazingly balanced.\n",
    "\n",
    "## Lets single out blue and red for a binary classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>colors</th>\n",
       "      <th>cmc</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>Volcanic Strength</td>\n",
       "      <td>Red</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Enchant creature Enchanted creature gets +2/+2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Unnatural Speed</td>\n",
       "      <td>Red</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Target creature gains haste until end of turn.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>Fling</td>\n",
       "      <td>Red</td>\n",
       "      <td>2.0</td>\n",
       "      <td>As an additional cost to cast This, sacrifice ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>Master Transmuter</td>\n",
       "      <td>Blue</td>\n",
       "      <td>4.0</td>\n",
       "      <td>{1}, Tap , Return an artifact you control to i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Vedalken Engineer</td>\n",
       "      <td>Blue</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Tap : Add two mana of any one color to your ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Goka the Unjust</td>\n",
       "      <td>Red</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Tap : This deals 4 damage to target creature t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name colors  cmc  \\\n",
       "1801  Volcanic Strength    Red  2.0   \n",
       "341     Unnatural Speed    Red  1.0   \n",
       "1966              Fling    Red  2.0   \n",
       "1435  Master Transmuter   Blue  4.0   \n",
       "200   Vedalken Engineer   Blue  2.0   \n",
       "275     Goka the Unjust    Red  4.0   \n",
       "\n",
       "                                                   text  \n",
       "1801  Enchant creature Enchanted creature gets +2/+2...  \n",
       "341      Target creature gains haste until end of turn.  \n",
       "1966  As an additional cost to cast This, sacrifice ...  \n",
       "1435  {1}, Tap , Return an artifact you control to i...  \n",
       "200   Tap : Add two mana of any one color to your ma...  \n",
       "275   Tap : This deals 4 damage to target creature t...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UG = modern.loc[modern['colors'].isin(['Blue', 'Red'])]\n",
    "\n",
    "UG.reset_index(inplace=True)\n",
    "UG.pop('index')\n",
    "\n",
    "UG[['name', 'colors', 'cmc', 'text']].sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blue</th>\n",
       "      <th>Red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Blue  Red\n",
       "0   1.0  0.0\n",
       "1   0.0  1.0\n",
       "2   1.0  0.0\n",
       "3   1.0  0.0\n",
       "4   1.0  0.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = pd.get_dummies(UG.colors)\n",
    "dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2361L, 815L)\n",
      "(2361L, 2L)\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "(2361L, 815L)\n",
      "(2361L, 2L)\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "There are 815 words in the vocabulary.\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "vec_X = vectorizer.fit_transform(UG['text'])\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(vec_X, dummies,\n",
    "                                             random_state=42)\n",
    "\n",
    "xTrain = np.asarray(xTrain.todense())\n",
    "xTest  = np.asarray(xTest.todense())\n",
    "yTrain = np.asarray(yTrain)\n",
    "yTest  = np.asarray(yTest)\n",
    "\n",
    "print xTrain.shape\n",
    "print yTrain.shape\n",
    "print type(xTrain)\n",
    "print type(yTrain)\n",
    "\n",
    "# xTrain = xTrain.reshape(-1, 1, 1, 815)\n",
    "# xTest = xTest.reshape(-1, 1, 1, 815)\n",
    "\n",
    "print xTrain.shape\n",
    "print yTrain.shape\n",
    "print type(xTrain)\n",
    "print type(yTrain)\n",
    "\n",
    "print \"There are {:,} words in the vocabulary.\".format(len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 0  Test: 0.651842439644  Train: 0.629394324439\n",
      "Round: 30  Test: 0.810673443456  Train: 0.831427361288\n",
      "Round: 60  Test: 0.833545108005  Train: 0.849216433715\n",
      "Round: 90  Test: 0.853875476493  Train: 0.861075815332\n",
      "Round: 120  Test: 0.852604828463  Train: 0.866581956798\n",
      "Round: 150  Test: 0.855146124524  Train: 0.873358746294\n",
      "Round: 180  Test: 0.861499364676  Train: 0.879288437103\n",
      "Round: 210  Test: 0.864040660737  Train: 0.885218127912\n",
      "Round: 240  Test: 0.870393900889  Train: 0.889030072003\n",
      "Round: 270  Test: 0.866581956798  Train: 0.892842016095\n",
      "Round: 300  Test: 0.866581956798  Train: 0.894536213469\n",
      "Round: 330  Test: 0.869123252859  Train: 0.894112664125\n",
      "Round: 360  Test: 0.87166454892  Train: 0.895383312156\n",
      "Round: 390  Test: 0.87166454892  Train: 0.895806861499\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "from theano import tensor as T\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn\n",
    "# %matplotlib inline\n",
    "\n",
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def init_weights(shape):\n",
    "    (h, w) = shape\n",
    "    normalizer = 2.0 * sqrt(6) / sqrt(h + w) * .2  #factors: correct for uni[0,1], glo, glo, softmax deriv\n",
    "    return theano.shared(floatX((np.random.random_sample(shape) - 0.5) \\\n",
    "                                * normalizer))  #code for using Glorot init\n",
    "    \n",
    "def model(X, w):\n",
    "    return T.nnet.softmax(T.dot(X, w))\n",
    "\n",
    "def adaDelta(cost, params, eta=0.2, rho=0.9, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        #calc g-squared\n",
    "        gSq = theano.shared(p.get_value() * 0.)\n",
    "        dwSq = theano.shared(p.get_value() * 0.)\n",
    "\n",
    "        #exp smoothed g squared\n",
    "        gSqNew = rho * gSq + (1 - rho) * g * g\n",
    "\n",
    "        #calc dx-squared\n",
    "        dw = eta * T.sqrt(dwSq + epsilon) * g / T.sqrt(gSq + epsilon)\n",
    "        dwSqNew = rho * dwSq + (1 - rho) * dw * dw\n",
    "\n",
    "        updates.append((dwSq, dwSqNew))\n",
    "        updates.append((gSq, gSqNew))\n",
    "        updates.append((p, p - dw))\n",
    "    return updates\n",
    "\n",
    "X = T.fmatrix()\n",
    "Y = T.fmatrix()\n",
    "# grad_list = theano.shared(np.array([0,0]), name='grad_list')\n",
    "\n",
    "w = init_weights((815 , 2))\n",
    "\n",
    "py_x = model(X, w)\n",
    "y_pred = T.argmax(py_x, axis=1)\n",
    "\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(py_x, Y))\n",
    "gradient = T.grad(cost=cost, wrt=w)\n",
    "update = [[w, w - gradient * 0.1]]\n",
    "\n",
    "train = theano.function(inputs=[X, Y], \n",
    "                        outputs=[cost, gradient], \n",
    "                        updates=update, \n",
    "                        allow_input_downcast=True)\n",
    "\n",
    "predict = theano.function(inputs=[X], \n",
    "                          outputs=y_pred, \n",
    "                          allow_input_downcast=True)\n",
    "\n",
    "\n",
    "for i in range(401):\n",
    "# #     for start, end in zip(range(0, xTrain.shape[0], 128), \n",
    "# #                           range(128, xTrain.shape[0], 128)):\n",
    "# #         cost, gradient = train(xTrain[start:end], yTrain[start:end])\n",
    "    cost, gradient = train(xTrain, yTrain)\n",
    "    if i % 30 == 0: \n",
    "        tr = np.mean(np.argmax(yTest, axis=1) == predict(xTest))\n",
    "        trr =  np.mean(np.argmax(yTrain, axis=1) == predict(xTrain))\n",
    "        print 'Round:', i,\" Test:\", tr, ' Train:', trr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Five Vs All Five\n",
    "\n",
    "And now the main event. Five way classification of all the colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5905L, 1161L)\n",
      "(5905L, 5L)\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "(5905L, 1161L)\n",
      "(5905L, 5L)\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "There are 1,161 words in the vocabulary.\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "y = pd.get_dummies(modern.colors)\n",
    "\n",
    "X = vectorizer.fit_transform(modern.text)\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X, y, random_state=42)\n",
    "\n",
    "xTrain = np.asarray(xTrain.todense())\n",
    "xTest  = np.asarray(xTest.todense())\n",
    "yTrain = np.asarray(yTrain)\n",
    "yTest  = np.asarray(yTest)\n",
    "\n",
    "print xTrain.shape\n",
    "print yTrain.shape\n",
    "print type(xTrain)\n",
    "print type(yTrain)\n",
    "\n",
    "# xTrain = xTrain.reshape(-1, 1, 1, 815)\n",
    "# xTest = xTest.reshape(-1, 1, 1, 815)\n",
    "\n",
    "print xTrain.shape\n",
    "print yTrain.shape\n",
    "print type(xTrain)\n",
    "print type(yTrain)\n",
    "\n",
    "print \"There are {:,} words in the vocabulary.\".format(len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 0  Test: 0.292026409345  Train: 0.27366638442\n",
      "Round: 500  Test: 0.601320467242  Train: 0.633192209992\n",
      "Round: 1000  Test: 0.627729812087  Train: 0.667739204064\n",
      "Round: 1500  Test: 0.641442356526  Train: 0.686875529213\n",
      "Round: 2000  Test: 0.655662772981  Train: 0.700423370025\n",
      "Round: 2500  Test: 0.66124936516  Train: 0.709060118544\n",
      "Round: 3000  Test: 0.664296597257  Train: 0.716680779001\n",
      "Round: 3500  Test: 0.676485525648  Train: 0.724132091448\n",
      "Round: 4000  Test: 0.682579989843  Train: 0.728704487722\n",
      "Round: 4500  Test: 0.687150837989  Train: 0.732938187976\n",
      "Round: 5000  Test: 0.688674454038  Train: 0.737849280271\n",
      "Round: 5500  Test: 0.688674454038  Train: 0.739881456393\n",
      "Round: 6000  Test: 0.686642965973  Train: 0.741913632515\n",
      "Round: 6500  Test: 0.691721686135  Train: 0.744623200677\n",
      "Round: 7000  Test: 0.694261046216  Train: 0.746655376799\n",
      "Round: 7500  Test: 0.695784662265  Train: 0.749364944962\n",
      "Round: 8000  Test: 0.695784662265  Train: 0.750381033023\n",
      "Round: 8500  Test: 0.694768918233  Train: 0.751905165114\n",
      "Round: 9000  Test: 0.695784662265  Train: 0.754445385267\n",
      "Round: 9500  Test: 0.696800406298  Train: 0.756816257409\n",
      "Round: 10000  Test: 0.698831894363  Train: 0.75766299746\n",
      "Wall time: 7min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn\n",
    "# %matplotlib inline\n",
    "\n",
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def init_weights(shape):\n",
    "    (h, w) = shape\n",
    "    normalizer = 2.0 * sqrt(6) / sqrt(h + w) * .2  #factors: correct for uni[0,1], glo, glo, softmax deriv\n",
    "    return theano.shared(floatX((np.random.random_sample(shape) - 0.5) \\\n",
    "                                * normalizer))  #code for using Glorot init\n",
    "    \n",
    "def model(X, w):\n",
    "    return T.nnet.softmax(T.dot(X, w))\n",
    "\n",
    "def adaDelta(cost, params, eta=0.2, rho=0.9, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        #calc g-squared\n",
    "        gSq = theano.shared(p.get_value() * 0.)\n",
    "        dwSq = theano.shared(p.get_value() * 0.)\n",
    "\n",
    "        #exp smoothed g squared\n",
    "        gSqNew = rho * gSq + (1 - rho) * g * g\n",
    "\n",
    "        #calc dx-squared\n",
    "        dw = eta * T.sqrt(dwSq + epsilon) * g / T.sqrt(gSq + epsilon)\n",
    "        dwSqNew = rho * dwSq + (1 - rho) * dw * dw\n",
    "\n",
    "        updates.append((dwSq, dwSqNew))\n",
    "        updates.append((gSq, gSqNew))\n",
    "        updates.append((p, p - dw))\n",
    "    return updates\n",
    "\n",
    "X = T.fmatrix()\n",
    "Y = T.fmatrix()\n",
    "\n",
    "w = init_weights((len(vectorizer.vocabulary_) , yTest.shape[1]))\n",
    "\n",
    "py_x = model(X, w)\n",
    "y_pred = T.argmax(py_x, axis=1)\n",
    "\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(py_x, Y))\n",
    "gradient = T.grad(cost=cost, wrt=w)\n",
    "update = [[w, w - gradient * 0.1]]\n",
    "\n",
    "train = theano.function(inputs=[X, Y], \n",
    "                        outputs=[cost, gradient], \n",
    "                        updates=update, \n",
    "                        allow_input_downcast=True)\n",
    "\n",
    "predict = theano.function(inputs=[X], \n",
    "                          outputs=y_pred, \n",
    "                          allow_input_downcast=True)\n",
    "\n",
    "\n",
    "for i in range(10001):\n",
    "# #     for start, end in zip(range(0, xTrain.shape[0], 128), \n",
    "# #                           range(128, xTrain.shape[0], 128)):\n",
    "# #         cost, gradient = train(xTrain[start:end], yTrain[start:end])\n",
    "    cost, gradient = train(xTrain, yTrain)\n",
    "    if i % 500 == 0: \n",
    "        tr = np.mean(np.argmax(yTest, axis=1) == predict(xTest))\n",
    "        trr =  np.mean(np.argmax(yTrain, axis=1) == predict(xTrain))\n",
    "        print 'Round:', i,\" Test:\", tr, ' Train:', trr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazing results, almost equal to logistic regression at 5min. \n",
    "\n",
    "### 4-Layer Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 0  Test: 0.27780599289  Train: 0.302116850127\n",
      "Round: 10  Test: 0.280853224987  Train: 0.287552921253\n",
      "Round: 20  Test: 0.46063991874  Train: 0.49483488569\n",
      "Round: 30  Test: 0.602336211275  Train: 0.63200677392\n",
      "Round: 40  Test: 0.653631284916  Train: 0.690770533446\n",
      "Round: 50  Test: 0.672930421534  Train: 0.734462320068\n",
      "Round: 60  Test: 0.691213814119  Train: 0.759017781541\n",
      "Round: 70  Test: 0.694261046216  Train: 0.774259102456\n",
      "Round: 80  Test: 0.699847638395  Train: 0.788653683319\n",
      "Round: 90  Test: 0.710512950736  Train: 0.805927180356\n",
      "Round: 100  Test: 0.723209751143  Train: 0.818797629128\n",
      "Round: 110  Test: 0.723717623159  Train: 0.832345469941\n",
      "Round: 120  Test: 0.729304215338  Train: 0.847417442845\n",
      "Round: 130  Test: 0.725241239208  Train: 0.853852667231\n",
      "Round: 140  Test: 0.727272727273  Train: 0.86316680779\n",
      "Round: 150  Test: 0.733875063484  Train: 0.872650296359\n",
      "Round: 160  Test: 0.723717623159  Train: 0.878577476715\n",
      "Round: 170  Test: 0.732351447435  Train: 0.885012701101\n",
      "Round: 180  Test: 0.731843575419  Train: 0.890939881456\n",
      "Round: 190  Test: 0.733367191468  Train: 0.897713801863\n",
      "Round: 200  Test: 0.724225495175  Train: 0.901270110076\n",
      "Round: 210  Test: 0.732351447435  Train: 0.90533446232\n",
      "Round: 220  Test: 0.728796343321  Train: 0.910922946655\n",
      "Round: 230  Test: 0.729304215338  Train: 0.91532599492\n",
      "Round: 240  Test: 0.73031995937  Train: 0.918035563082\n",
      "Round: 250  Test: 0.728288471305  Train: 0.919559695174\n",
      "Round: 260  Test: 0.731335703403  Train: 0.922946655377\n",
      "Round: 270  Test: 0.727780599289  Train: 0.92616426757\n",
      "Round: 280  Test: 0.730827831386  Train: 0.928196443692\n",
      "Round: 290  Test: 0.732351447435  Train: 0.930059271804\n",
      "Round: 300  Test: 0.727272727273  Train: 0.931752751905\n",
      "Round: 310  Test: 0.72625698324  Train: 0.933954276037\n",
      "Round: 320  Test: 0.725749111224  Train: 0.934292972058\n",
      "Round: 330  Test: 0.721686135094  Train: 0.93683319221\n",
      "Round: 340  Test: 0.727272727273  Train: 0.937849280271\n",
      "Round: 350  Test: 0.724733367191  Train: 0.93734123624\n",
      "Round: 360  Test: 0.724225495175  Train: 0.939542760373\n",
      "Round: 370  Test: 0.72625698324  Train: 0.939881456393\n",
      "Round: 380  Test: 0.73031995937  Train: 0.942252328535\n",
      "Round: 390  Test: 0.724225495175  Train: 0.942929720576\n",
      "Round: 400  Test: 0.726764855256  Train: 0.943607112616\n",
      "Wall time: 3min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "import numpy as np\n",
    "\n",
    "srng = RandomStreams()\n",
    "\n",
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def init_weights(shape):\n",
    "    return theano.shared(floatX(np.random.randn(*shape) * 0.01))\n",
    "\n",
    "def rectify(X, alpha=1.0):\n",
    "#     return T.maximum(X, 0.)\n",
    "    return T.maximum(X, 0.05*X)  #leaky rectifier\n",
    "#     return T.switch(X > 0, X, alpha * (T.exp(X) - 1)) # ELU\n",
    "\n",
    "def softmax(X):\n",
    "    e_x = T.exp(X - X.max(axis=1).dimshuffle(0, 'x'))\n",
    "    return e_x / e_x.sum(axis=1).dimshuffle(0, 'x')\n",
    "\n",
    "def RMSprop(cost, params, lr=0.001, rho=0.9, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        acc = theano.shared(p.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
    "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
    "        g = g / gradient_scaling\n",
    "        updates.append((acc, acc_new))\n",
    "        updates.append((p, p - lr * g))\n",
    "    return updates\n",
    "\n",
    "def dropout(X, p=0.):\n",
    "    if p > 0:\n",
    "        retain_prob = 1 - p\n",
    "        X *= srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n",
    "        X /= retain_prob\n",
    "    return X\n",
    "\n",
    "def model(X, w_h, w_h2, w_o, p_drop_input, p_drop_hidden):\n",
    "    X = dropout(X, p_drop_input)\n",
    "    h = rectify(T.dot(X, w_h))\n",
    "\n",
    "    h = dropout(h, p_drop_hidden)\n",
    "    h2 = rectify(T.dot(h, w_h2))\n",
    "\n",
    "    h2 = dropout(h2, p_drop_hidden)\n",
    "    py_x = softmax(T.dot(h2, w_o))\n",
    "    return h, h2, py_x\n",
    "\n",
    "X = T.fmatrix()\n",
    "Y = T.fmatrix()\n",
    "\n",
    "# w = init_weights((len(vectorizer.vocabulary_) , yTest.shape[1])) # old \n",
    "w_h = init_weights((len(vectorizer.vocabulary_), 600))\n",
    "w_h2 = init_weights((600, 600))\n",
    "w_o = init_weights((600, yTest.shape[1]))\n",
    "\n",
    "noise_h, noise_h2, noise_py_x = model(X, w_h, w_h2, w_o, 0.2, 0.5)\n",
    "h, h2, py_x = model(X, w_h, w_h2, w_o, 0., 0.)\n",
    "y_x = T.argmax(py_x, axis=1)\n",
    "\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(noise_py_x, Y))\n",
    "params = [w_h, w_h2, w_o]\n",
    "updates = RMSprop(cost, params, lr=0.0001)\n",
    "\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "predict = theano.function(inputs=[X], outputs=y_x, allow_input_downcast=True)\n",
    "\n",
    "for i in range(401):\n",
    "    for start, end in zip(range(0, len(xTrain), 128), range(128, len(xTrain), 128)):\n",
    "        cost = train(xTrain[start:end], yTrain[start:end])\n",
    "    if i%10 == 0: \n",
    "        tr = np.mean(np.argmax(yTest, axis=1) == predict(xTest))\n",
    "        trr =  np.mean(np.argmax(yTrain, axis=1) == predict(xTrain))\n",
    "        print 'Round:', i,\" Test:\", tr, ' Train:', trr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strong signs of overfitting\n",
    "\n",
    "Next steps:  \n",
    "\n",
    "Leaky RELU swapped out for ELU, alpha = 1.0   \n",
    "Train accuracy dropped by 14% (good)  \n",
    "Test accuracy dropped by 3% (bad)   \n",
    "\n",
    "Leaky RELU swapped out for ELU, alpha = .5  \n",
    "Train accuracy dropped by 7% (good)  \n",
    "Test accuracy dropped by 1% (bad)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
